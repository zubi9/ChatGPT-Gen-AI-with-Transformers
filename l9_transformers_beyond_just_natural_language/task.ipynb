{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformers Beyond Just Natural Language\n",
    "\n",
    "In this notebook, there multiple tasks that you can choose from. Choosing one should suffice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic Similarity\n",
    "\n",
    "In this directory, there is a JSON file containing the abstracts of the scientific papers in the DIT publication database. Each abstract has a set of co-authors. With the use of transformers, construct the latent space of this database. After finding the Euclidean distances between the paper embeddings, find the distances between every possible pair of authors. Finally, for every author, recommend 5 authors that are the closest (and not co-authors). This should pair the authors by semantic similarity of research papers. These close authors should have a cup of coffee and discuss a potential collaboration.\n",
    "\n",
    "Feel free to map the embeddings of the papers using a mapping method of your choosing and display it on a 2D plane. Further clustering using k-means is also an option to get the different clusters in the latent space. If you clustered your embeddings (maybe 5 to 8 clusters), apply KeyBERT to extract the keywords of each cluster and display them in Wordclouds to observe the semantic topics of each cluster. \n",
    "\n",
    "\n",
    "For this task, the paper titled `Topical Clustering` can help in some parts. (https://jas.bayern/index.php/bjas/article/view/135)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image/Speech Classification\n",
    "\n",
    "In order to give freedom to students when it comes to the application of transformers, design a task for yourself to classify images using a vision transformers, or to classify speech (maybe based on language) using time-series transformers."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
